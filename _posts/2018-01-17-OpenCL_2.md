---
layout: post
title: "OpenCL notes_2 data transfer and parition"
description: "OpenCL notes_2 data transfer and parition"
categories: [OpenCL]
tags: [parallel, OpenCL]
redirect_from:
  - /2018/01/17/
---

## 1. Kernel Args
```
cl_int clSetKernelArg ( cl_kernel kernel,
  cl_uint arg_index,
  size_t arg_size,
  const void *arg_value)
```
`index` is the position of argument in `__kernel` function. `arg_value` is the corresponding value. The argument data pointed to by `arg_value` is copied and the `arg_value` pointer can be reused by the application. 
If the argument is a memory object(complex data), the arg_value entry will be a pointer to the appropriate buffer, pipe, image or image array object. The memory object must be created with the context associated with the kernel object.
```
clSetKernelArg(proc, 0, sizeof(num), &num);
clSetKernelArg(proc, 0, sizeof(mem_obj), &mem_obj);
```
In OpenCL, memory objects are represented by `cl_mem` data structure, and they come in two types: **buffer objects** and **image objects**. 

## 2. Buffer Objects
Buffer objects package any type of data that doesn't involve images. 
```
cl_mem clCreateBuffer ( cl_context context,
  cl_mem_flags flags,
  size_t size,
  void *host_ptr,
  cl_int *errcode_ret)
```
This returns a `cl_mem` that wraps around the data identified by the `host_ptr` argument. 
-**Accessibility**: `CL_MEM_READ_WRITE`, `CL_MEM_WRITE_ONLY`, `CL_MEM_READ_ONLY`
-**Memory_Allocation**: `CL_MEM_USE_HOST_PTR`, `CL_MEM_ALLOC_HOST_PTR`, `CL_MEM_COPY_HOST_PTR`, `CL_MEM_HOST_WRITE_ONLY`
```
vec_buff = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR), sizeof(float) * 32, vec, &error);
```
If you're running host applications on a memory-limited system or on the same device that you're using to process kernels, set the `CL_MEM_USE_HOST_PTR` flag. 
If low memory isn't an issue but reliable data transfer is, set `CL_MEM_COPY_HOST_PTR`. 

### 2.1 Subbuffer
```
cl_mem clCreateSubBuffer (  cl_mem buffer,
  cl_mem_flags flags,
  cl_buffer_create_type buffer_create_type,
  const void *buffer_create_info,
  cl_int *errcode_ret)
```
`buffer_create_type` must by `CL_BUFFER_CREATE_TYPE_REGION`, and the fourth arg expects a pointer to a `_cl_buffer_region` structure. 
```
typedef struct _cl_buffer_region {
    size_t origin;
    size_t size;
} cl_buffer_region;
```
The `origin` field specifies the start of the subbuffer's data inside the buffer. The `size` field defines the size of the buffer. 

## 3. Image Objects
OpenCL provides a specific type of memory object for holding pixel data. The standard refers to them as **image objects**. 
```
cl_mem clCreateImage (  cl_context context,
  cl_mem_flags flags,
  const cl_image_format *image_format,
  const cl_image_desc *image_desc,
  void *host_ptr,
  cl_int *errcode_ret)
```
```
typedef struct _cl_image_format {
          cl_channel_order image_channel_order;
          cl_channel_type  image_channel_data_type;
} cl_image_format;
```

## 4. Info on Buffer Objects
```
cl_int clGetMemObjectInfo ( cl_mem  memobj ,
  cl_mem_info  param_name ,
  size_t  param_value_size ,
  void  *param_value ,
  size_t  *param_value_size_ret )
```
The first three arguments provide input: the memory object, a name that identifies the type of data you're requesting, and the amount of data you're requesting. The last two arguments are output arguments, in which the function returns the data you're requesting and the size of the returned data. 
```
float main_data[100];
cl_mem main_buffer, sub_buffer;
void *main_buffer_mem = NULL, *sub_buffer_mem = NULL;
size_t main_buffer_size, sub_buffer_size;
cl_buffer_region region;
...
main_buffer = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(main_data), main_data, &err);
if (err < 0) {
    perror("Couldn't create a buffer\n");
    exit(1);
}
region.origin = 30 * sizeof(float);
region.size = 20 * sizeof(float);
sub_buffer = clCreateSubBuffer(main_buffer, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, &region, &err);
if (err < 0) {
    perror("Couldn't create a sub-buffer\n");
    exit(1);
}
clGetMemObjectInfo(main_buffer, CL_MEM_SIZE, 
    sizeof(main_buffer_size), &main_buffer_size, NULL);
clGetMemObjectInfo(sub_buffer, CL_MEM_SIZE, 
    sizeof(sub_buffer_size), &sub_buffer_size, NULL);
```
## 5. Memory Object Transfer
### 5.1 Read/Write
To read a buffer object from a device to the host, we can simply call `clEnqueueReadBuffer`.
```
clEnqueueReadBuffer(cl_command_queue queue, cl_mem buffer, cl_bool blocking, size_t offset, size_t data_size, void* ptr, cl_uint num_events, const cl_event* wait_list, cl_event* event);
clEnqueueWriteBuffer(cl_command_queue queue, cl_mem buffer, cl_bool blocking, size_t offset, size_t data_size, void* ptr, cl_uint num_events, const cl_event* wait_list, cl_event* event);
```
Each of these functions also have a boolean argument called `blocking`. If this is set to `CL_TRUE`, the function won't return until the read/write operation is finished. 
### 5.2 Mapping memory objects
When a regular C/C++ application needs to access a file, it's common to place the file's content in memory and read or modify it using memory operations. This is referred to as **memory-mapping** the file. You can also map a memory object on a device to a memory region on the host. 
```
void * clEnqueueMapBuffer (	cl_command_queue command_queue,
 	cl_mem buffer,
 	cl_bool blocking_map,
 	cl_map_flags map_flags,
 	size_t offset,
 	size_t size,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event,
 	cl_int *errcode_ret);
 
void * clEnqueueMapImage (	cl_command_queue  command_queue ,
 	cl_mem  image ,
 	cl_bool  blocking_map ,
 	cl_map_flags  map_flags ,
 	const size_t  * origin ,
 	const size_t  * region ,
 	size_t  *image_row_pitch ,
 	size_t  *image_slice_pitch ,
 	cl_uint  num_events_in_wait_list ,
 	const cl_event  *event_wait_list ,
 	cl_event  *event ,
 	cl_int  *errcode_ret )
```
The return pointer identifies the start of mapped memory on the host. 
Memory mapping provides a significant improvement in performance over regular read/write operation. 

### 5.3 Memory copy
```
cl_int clEnqueueCopyBuffer (	cl_command_queue command_queue,
 	cl_mem src_buffer,
 	cl_mem dst_buffer,
 	size_t src_offset,
 	size_t dst_offset,
 	size_t size,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)

cl_int clEnqueueCopyImage (	cl_command_queue command_queue,
 	cl_mem src_image,
 	cl_mem dst_image,
 	const size_t *src_origin,
 	const size_t *dst_origin,
 	const size_t *region,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)

cl_int clEnqueueCopyImage (	cl_command_queue command_queue,
 	cl_mem src_image,
 	cl_mem dst_image,
 	const size_t *src_origin,
 	const size_t *dst_origin,
 	const size_t *region,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)

cl_int clEnqueueCopyImageToBuffer (	cl_command_queue command_queue,
 	cl_mem src_image,
 	cl_mem  dst_buffer,
 	const size_t *src_origin,
 	const size_t *region,
 	size_t dst_offset,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)

cl_int clEnqueueCopyBufferToImage (	cl_command_queue command_queue,
 	cl_mem src_buffer,
 	cl_mem  dst_image,
 	size_t src_offset,
 	const size_t *dst_origin,
 	const size_t *region,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)

cl_int clEnqueueCopyBufferRect (	cl_command_queue command_queue,
 	cl_mem src_buffer,
 	cl_mem dst_buffer,
 	const size_t *src_origin,
 	const size_t *dst_origin,
 	const size_t *region,
 	size_t src_row_pitch,
 	size_t src_slice_pitch,
 	size_t dst_row_pitch,
 	size_t dst_slice_pitch,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)
```

## 6. Data Partitioning
The better you distribute the processing load, the sonner your computational tasks will be finished. 
```
cl_int clEnqueueNDRangeKernel (	cl_command_queue command_queue,
 	cl_kernel kernel,
 	cl_uint work_dim,
 	const size_t *global_work_offset,
 	const size_t *global_work_size,
 	const size_t *local_work_size,
 	cl_uint num_events_in_wait_list,
 	const cl_event *event_wait_list,
 	cl_event *event)
```
- work_dims: the number of dimensions in the data
- global_work_offset: the global ID offsets in each dimension
- global_work_size: the number of work-items in each dimension
- local_work_size: the number of work-items in a work-group, in each dimension

```
for (i = 0; i < Z; i++) {
    for (j = 0; j < Y; j++) {
        for (k = 0; k < X; k++) {
            process(point[i][j][k]);
        }
    }
}
```
Kernel only executes code that would lie inside the innermost loop->**work_item**
The array`{i,j,k}` are called **global ID**.The number of elements in a global ID is referred to as the data's **dimensionality**. `clEnqueueNDRangeKernel`
A **work-group** is a combination of work-items that access the same processing resources. When it comes to programming, work-groups have two main advantages:
(1): Work-items in a work-group can access the same block of high-speed memory called local memory.
(2): Work-items in a work-group can be synchronized using fences and barriers. 
